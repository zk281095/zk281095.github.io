<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>中文分词学习ing | Kai&#39;sBlog</title>

  <!-- keywords -->
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="stanford nlp测试使用stanford-corenlp-3.8.0.jar 导入时引入此包，其他的-javadoc/models/sources，不对。 分词配置进行中文分词前需要进行配置，字典等等一些内容Stanford CoreNLP 进行中文分词 1StanfordCoreNLP pipeline = new StanfordCoreNLP(&quot;CoreNLP-chinese.pro">
<meta property="og:type" content="article">
<meta property="og:title" content="中文分词学习ing">
<meta property="og:url" content="http://zk281095.github.io/2017/08/14/中文分词/index.html">
<meta property="og:site_name" content="Kai&#39;sBlog">
<meta property="og:description" content="stanford nlp测试使用stanford-corenlp-3.8.0.jar 导入时引入此包，其他的-javadoc/models/sources，不对。 分词配置进行中文分词前需要进行配置，字典等等一些内容Stanford CoreNLP 进行中文分词 1StanfordCoreNLP pipeline = new StanfordCoreNLP(&quot;CoreNLP-chinese.pro">
<meta property="og:updated_time" content="2017-08-23T09:31:28.439Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="中文分词学习ing">
<meta name="twitter:description" content="stanford nlp测试使用stanford-corenlp-3.8.0.jar 导入时引入此包，其他的-javadoc/models/sources，不对。 分词配置进行中文分词前需要进行配置，字典等等一些内容Stanford CoreNLP 进行中文分词 1StanfordCoreNLP pipeline = new StanfordCoreNLP(&quot;CoreNLP-chinese.pro">
  
    <link rel="alternative" href="/atom.xml" title="Kai&#39;sBlog" type="application/atom+xml">
  
  
    <link rel="icon" href="https://gss0.baidu.com/-Po3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/4afbfbedab64034f236c6fd6adc379310b551db8.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  
  

  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
</head>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="https://gss0.baidu.com/-Po3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/4afbfbedab64034f236c6fd6adc379310b551db8.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Kai</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://github.com/smackgg/hexo-theme-smackdown">smackdown</a>
			        
			        </div>
				</section>
				

				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Kai</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="https://gss0.baidu.com/-Po3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/4afbfbedab64034f236c6fd6adc379310b551db8.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Kai</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-中文分词" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/08/14/中文分词/" class="article-date">
  	<time datetime="2017-08-14T02:30:15.000Z" itemprop="datePublished">2017-08-14</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      中文分词学习ing
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
        

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="stanford-nlp测试使用"><a href="#stanford-nlp测试使用" class="headerlink" title="stanford nlp测试使用"></a>stanford nlp测试使用</h2><p><strong><em>stanford-corenlp-3.8.0.jar 导入时引入此包，其他的-javadoc/models/sources，不对。</em></strong></p>
<h4 id="分词配置"><a href="#分词配置" class="headerlink" title="分词配置"></a>分词配置</h4><p>进行中文分词前需要进行配置，字典等等一些内容<br><a href="http://blog.csdn.net/macanv/article/details/72993873?utm_source=itdadao&amp;utm_medium=referral" target="_blank" rel="external">Stanford CoreNLP 进行中文分词</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">StanfordCoreNLP pipeline = new StanfordCoreNLP(<span class="string">"CoreNLP-chinese.properties"</span>);</div></pre></td></tr></table></figure>
<p>其中<code>ClassLoader.getResourceAsStream</code>按照以上String的类型会直接读取class根目录下的properties文件。</p>
<h4 id="自定义词典的properties文件："><a href="#自定义词典的properties文件：" class="headerlink" title="自定义词典的properties文件："></a>自定义词典的properties文件：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Pipeline options - lemma is no-op for Chinese but currently needed because coref demands it (bad old requirements system)</span></div><div class="line">   annotators = segment, ssplit, pos, lemma, ner, parse, sentiment</div><div class="line"></div><div class="line">   <span class="comment"># segment</span></div><div class="line">   customAnnotatorClass.segment = edu.stanford.nlp.pipeline.ChineseSegmenterAnnotator</div><div class="line"></div><div class="line">   segment.model = edu/stanford/nlp/models/segmenter/chinese/pku.gz</div><div class="line">   segment.sighanCorporaDict = edu/stanford/nlp/models/segmenter/chinese</div><div class="line">   segment.serDictionary = edu/stanford/nlp/models/segmenter/chinese/dict-chris6.ser.gz,data/userdict_namenentity_1.1.txt</div><div class="line">   segment.sighanPostProcessing = <span class="literal">true</span></div><div class="line"></div><div class="line">   <span class="comment"># sentence split</span></div><div class="line">   ssplit.boundaryTokenRegex = [.]|[!?]+|[\u3002]|[\uFF01\uFF1F]+</div><div class="line"></div><div class="line">   <span class="comment"># pos</span></div><div class="line">   pos.model = edu/stanford/nlp/models/pos-tagger/chinese-distsim/chinese-distsim.tagger</div><div class="line"></div><div class="line">   <span class="comment"># ner</span></div><div class="line">   ner.model = edu/stanford/nlp/models/ner/chinese.misc.distsim.crf.ser.gz</div><div class="line">   ner.applyNumericClassifiers = <span class="literal">false</span></div><div class="line">   ner.useSUTime = <span class="literal">false</span></div><div class="line"></div><div class="line">   <span class="comment">#parse</span></div><div class="line">   parse.model = edu/stanford/nlp/models/lexparser/chineseFactored.ser.gz</div><div class="line"></div><div class="line">   <span class="comment"># coref</span></div><div class="line">   coref.sieves = ChineseHeadMatch, ExactStringMatch, PreciseConstructs, StrictHeadMatch1, StrictHeadMatch2, StrictHeadMatch3, StrictHeadMatch4, PronounMatch</div><div class="line">   coref.input.type = raw</div><div class="line">   coref.postprocessing = <span class="literal">true</span></div><div class="line">   coref.calculateFeatureImportance = <span class="literal">false</span></div><div class="line">   coref.useConstituencyTree = <span class="literal">true</span></div><div class="line">   coref.useSemantics = <span class="literal">false</span></div><div class="line">   coref.md.type = RULE</div><div class="line">   coref.mode = hybrid</div><div class="line">   coref.path.word2vec =</div><div class="line">   coref.language = zh</div><div class="line">   coref.print.md.log = <span class="literal">false</span></div><div class="line">   coref.defaultPronounAgreement = <span class="literal">true</span></div><div class="line">   coref.zh.dict = edu/stanford/nlp/models/dcoref/zh-attributes.txt.gz</div></pre></td></tr></table></figure>
<p>data/userdict_namenentity_1.1.txt为用户自定义词典，工程根目录下创建data文件夹。</p>
<h4 id="命名实体识别"><a href="#命名实体识别" class="headerlink" title="命名实体识别"></a>命名实体识别</h4><p>stanford ner不提供模型扩展，因此只能自己训练模型来完成命名实体识别，需要语料和实体标注<br>不过提供训练方法，方式见<a href="https://nlp.stanford.edu/software/crf-faq.shtml" target="_blank" rel="external">FAQ</a></p>
<h2 id="Tire树"><a href="#Tire树" class="headerlink" title="Tire树"></a>Tire树</h2><p><strong><em>Tire树分词是词典树分词，将词建立树，然后分词时顺序读取句子字符匹配，完成分词。</em></strong></p>
<p>用Trie树词典分词就是按照句子的字符顺序从root往下走，每走到一个结束节点则分出一个词。中途遇到的中继节点统统忽略，这种方式也称“最长匹配”，是一种很武断的方式。<br>要想提高分词效果，就必须引入条件概率（隐马尔可夫模型），这就是Ansj分词的使命吧。</p>
<h2 id="DoubleArrayTire"><a href="#DoubleArrayTire" class="headerlink" title="DoubleArrayTire"></a>DoubleArrayTire</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">双数组Trie (Double-Array Trie)结构由日本人JUN-ICHI AOE于1989年提出的，</div><div class="line">是Trie结构的压缩形式，仅用两个线性数组来表示Trie树，该结构有效结合了数</div><div class="line">字搜索树(Digital Search Tree)检索时间高效的特点和链式表示的Trie空间结</div><div class="line">构紧凑的特点。双数组Trie的本质是一个确定有限状态自动机（DFA），每个节</div><div class="line">点代表自动机的一个状态，根据变量不同，进行状态转移，当到达结束状态或</div><div class="line">无法转移时，完成一次查询操作。在双数组所有键中包含的字符之间的联系都是</div><div class="line">通过简单的数学加法运算表示，不仅提高了检索速度，而且省去了链式结构中使</div><div class="line">用的大量指针，节省了存储空间。</div><div class="line">                         ——《基于双数组Ｔｒｉｅ树算法的字典改进和实现》</div></pre></td></tr></table></figure>
<p>DoubleArrayTire理解为两个数组base和check来维护tire树</p>
<p><a href="http://www.hankcs.com/program/java/%E5%8F%8C%E6%95%B0%E7%BB%84trie%E6%A0%91doublearraytriejava%E5%AE%9E%E7%8E%B0.html" target="_blank" rel="external">文档</a></p>
<h2 id="看到的分词器代码的简单理解"><a href="#看到的分词器代码的简单理解" class="headerlink" title="看到的分词器代码的简单理解"></a>看到的分词器代码的简单理解</h2><p>中文分词器里面包含一个正向最大匹配分词器和一个逆向最大匹配分词器，但是先经过lucene分析器处理，然后通过两个分词器分割，选择最好的结果。</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/08/21/解决eclipse使用maven更新慢/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          解决Eclipse使用Maven更新慢的问题
        
      </div>
    </a>
  
  
    <a href="/2017/08/11/elasticsearch插件/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">elasticsearch插件</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="中文分词" data-title="中文分词学习ing" data-url="http://zk281095.github.io/2017/08/14/中文分词/"  data-images="https://gss0.baidu.com/-Po3dSag_xI4khGko9WTAnF6hhy/zhidao/pic/item/4afbfbedab64034f236c6fd6adc379310b551db8.jpg" data-content="中文分词学习ing">
    <div class="ds-share-inline">
      <ul  class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul>
      <div class="ds-share-icons-more">
      </div>
    </div>
 </div>
 





</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2017 Kai
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>